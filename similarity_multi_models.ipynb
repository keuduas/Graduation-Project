{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "708dc87f-704a-452b-812f-afc742d360b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from typing import Optional, List\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from torchvision.models import resnet50,ResNet50_Weights\n",
    "from torch import Tensor\n",
    "from matplotlib import cm\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "import os  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfd2b801-f3e9-4f83-9e37-3fbaa231abb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 记得在文件开头导入相应的模型和权重  \n",
    "from torchvision.models import (  \n",
    "    resnet50, resnet101, resnet18, resnet34,  \n",
    "    densenet121, densenet169, densenet201,  \n",
    "    vgg16, vgg19,  \n",
    "    efficientnet_b0, efficientnet_b1, efficientnet_b2,  \n",
    "    mobilenet_v2, mobilenet_v3_small, mobilenet_v3_large,  \n",
    "    shufflenet_v2_x0_5, shufflenet_v2_x1_0  \n",
    ")  \n",
    "from torchvision.models import (  \n",
    "    ResNet50_Weights, ResNet101_Weights, ResNet18_Weights, ResNet34_Weights,  \n",
    "    DenseNet121_Weights, DenseNet169_Weights, DenseNet201_Weights,  \n",
    "    VGG16_Weights, VGG19_Weights,  \n",
    "    EfficientNet_B0_Weights, EfficientNet_B1_Weights, EfficientNet_B2_Weights,  \n",
    "    MobileNet_V2_Weights, MobileNet_V3_Small_Weights, MobileNet_V3_Large_Weights,  \n",
    "    ShuffleNet_V2_X0_5_Weights, ShuffleNet_V2_X1_0_Weights  \n",
    ") \n",
    "def select_hook_layer(model, model_type):  \n",
    "        if model_type.startswith('resnet'):  \n",
    "            return model.layer4[-1]  \n",
    "        elif model_type.startswith('densenet'):  \n",
    "            return model.features[-1]  \n",
    "        elif model_type.startswith('vgg'):  \n",
    "            return model.features[-1]  \n",
    "        elif model_type.startswith('efficientnet'):  \n",
    "            return model.features[-1]  \n",
    "        elif model_type.startswith('mobilenet'):  \n",
    "            return model.features[-1]  \n",
    "        elif model_type.startswith('shufflenet'):  \n",
    "            return model.conv5  \n",
    "        else:  \n",
    "            raise ValueError(f\"Unsupported model type: {model_type}\") \n",
    "def process_image_withhooks(img_path, model_weights=ResNet50_Weights.DEFAULT):  \n",
    "    \"\"\"  \n",
    "    处理图片并计算特征和梯度的加权值donations_values  \n",
    "\n",
    "    Args:  \n",
    "        img_path (str): 输入图片的路径  \n",
    "        model_weights: 模型的预训练权重，默认为ResNet50的默认权重  \n",
    "\n",
    "    Returns:  \n",
    "        tensor: shape (num_classes,) 的 tensor，表示各个类别的donations_values  \n",
    "    \"\"\"  \n",
    "    # 定义预处理步骤  \n",
    "    test_transform = transforms.Compose([  \n",
    "        transforms.Resize(512),  \n",
    "        transforms.ToTensor(),  \n",
    "        transforms.Normalize(  \n",
    "            mean=[0.485, 0.456, 0.406],  \n",
    "            std=[0.229, 0.224, 0.225]  \n",
    "        )  \n",
    "    ])  \n",
    "\n",
    "    # 获取设备  \n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')  \n",
    "\n",
    "\n",
    "    # 初始化模型  \n",
    "    # model = resnet50(weights=model_weights).eval().to(device)  \n",
    "    model = vgg19(weights=VGG19_Weights.DEFAULT).eval().to(device) \n",
    "    # model = efficientnet_b0(weights=EfficientNet_B0_Weights.DEFAULT).eval().to(device) \n",
    "    \n",
    "    # print(f\"try to open image, path：{img_path}\")  \n",
    "    if not img_path.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):  \n",
    "        print(f\"跳过非图片文件：{img_path}\")  \n",
    "        return None  \n",
    "\n",
    "    # 加载图片  \n",
    "    img_pil = Image.open(img_path)  \n",
    "\n",
    "    # 预处理图片  \n",
    "    input_tensor = test_transform(img_pil).unsqueeze(0).to(device)  \n",
    "\n",
    "    # 定义前向hook  \n",
    "    def forward_hook(module, inp, outp):  \n",
    "        feature_map.append(outp)  \n",
    "\n",
    "    # 定义反向hook  \n",
    "    def backward_hook(module, inp, outp):  \n",
    "        grad.append(outp)  \n",
    "\n",
    "    # 初始化容器  \n",
    "    feature_map = []  \n",
    "    grad = []  \n",
    "    \n",
    "    # 使用示例  \n",
    "    hook_layer = select_hook_layer(model, type(model).__name__.lower())  \n",
    "    hook_handle = hook_layer.register_forward_hook(forward_hook)  \n",
    "    grad_hook_handle = hook_layer.register_full_backward_hook(backward_hook)  \n",
    "\n",
    "    try:  \n",
    "        # 前向传播  \n",
    "      \n",
    "        out = model(input_tensor)  \n",
    "        cls_idx = torch.argmax(out).item()  \n",
    "        # 计算预测类别分数  \n",
    "        score = out[:, cls_idx].sum()  \n",
    "\n",
    "        # 反向传播  \n",
    "        model.zero_grad()  \n",
    "        score.backward(retain_graph=False)  # 减少内存占用  \n",
    "\n",
    "        # 获取特征和梯度  \n",
    "        weights = grad[0][0].squeeze(0).mean(dim=(1, 2))  #GAP(a)\n",
    "        mean_values= feature_map[0].squeeze(0).mean(dim=(1, 2))  \n",
    "\n",
    "        # 计算加权后的值  \n",
    "        # donations_values = mean_values * weights  \n",
    "        donations_values = mean_values \n",
    "\n",
    "        return donations_values.detach().cpu()  \n",
    "\n",
    "    except Exception as e:  \n",
    "        print(f\"处理过程中出现错误：{e}\")  \n",
    "        return None  \n",
    "\n",
    "    finally:  \n",
    "        # 删除hook并清理数据  \n",
    "        hook_handle.remove()  \n",
    "        grad_hook_handle.remove()  \n",
    "        feature_map.clear()  \n",
    "        grad.clear()  \n",
    "\n",
    "        # 删除GPU上的张量并释放内存  \n",
    "        if input_tensor.is_cuda:  \n",
    "            del input_tensor  \n",
    "            torch.cuda.empty_cache()  \n",
    "\n",
    "        if 'out' in locals():  \n",
    "            del out  \n",
    "        if 'score' in locals():  \n",
    "            del score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6260618-30c3-44d0-908b-e387dda4a2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_path=\"dataset/波斯猫/1.jpg\"\n",
    "# donations_values=process_image_withhooks(img_path, model_weights=ResNet50_Weights.DEFAULT)\n",
    "# print(donations_values)\n",
    "# donations_values.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24703f6d-0643-48c6-a8c0-e37b9150dab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "\n",
    "# 配置PyTorch的内存分配参数，减少内存碎片  \n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'  \n",
    "\n",
    "def process_batch_images(class_path, batch_size=8, device=None):  \n",
    "    \"\"\"  \n",
    "    批量处理一个类别下的所有图片，并返回每张图片的donations_values  \n",
    "\n",
    "    Args:  \n",
    "        class_path (str): 类别图片的路径  \n",
    "        batch_size (int): 批次大小，缺省值为8  \n",
    "        device (str or torch.device, optional): 设备类型（\"cpu\" 或 \"cuda\"），缺省值为 None，会自动检测  \n",
    "\n",
    "    Returns:  \n",
    "        list: 包含每张图片的donations_values 的列表  \n",
    "    \"\"\"  \n",
    "    if device is None:  \n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  \n",
    "    print()\n",
    "    print(\"using device:\"+str(device))\n",
    "    print(\"analyse class:\"+str(class_path))\n",
    "    donations_values_list = []  \n",
    "\n",
    "    # 获取图片文件路径列表  \n",
    "    img_paths = [os.path.join(class_path, f) for f in os.listdir(class_path)  \n",
    "                 if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))]  \n",
    "\n",
    "    # 计算总批次数  \n",
    "    total_batches = len(img_paths) // batch_size  \n",
    "    if len(img_paths) % batch_size != 0:  \n",
    "        total_batches += 1  \n",
    "\n",
    "    succeed_img = 0\n",
    "    # 分批次处理图片  \n",
    "    for batch_idx in range(total_batches):  \n",
    "        start = batch_idx * batch_size  \n",
    "        end = min((batch_idx + 1) * batch_size, len(img_paths))  \n",
    "        batch_paths = img_paths[start:end]  \n",
    "\n",
    "        batch_features = []  \n",
    "\n",
    "        # 逐张处理图片以减少内存占用  \n",
    "        for img_path in batch_paths:  \n",
    "            try:  \n",
    "                # 使用process_image_withhooks处理图片  \n",
    "                donations_value = process_image_withhooks(img_path)  \n",
    "\n",
    "                if donations_value is not None:  \n",
    "                    # 添加到批次结果  \n",
    "                    # print(\"succeed to process image:\"+img_path)\n",
    "                    succeed_img += 1\n",
    "                    batch_features.append(donations_value)  \n",
    "\n",
    "            except Exception as e:  \n",
    "                print(f\"处理 {img_path} 时发生错误：{str(e)}\")  \n",
    "                continue  \n",
    "\n",
    "        # 如果批次中没有有效的特征，跳过  \n",
    "        if not batch_features:  \n",
    "            continue  \n",
    "\n",
    "        # 将批次的特征拼接到结果列表  \n",
    "        donations_values_list.extend(batch_features)  \n",
    "\n",
    "        # 释放当前批次的内存  \n",
    "        batch_features.clear()  \n",
    "\n",
    "    print(f\"all_imgs : {succeed_img}\")\n",
    "    return donations_values_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "343150cb-2a0c-4404-aeb3-ed6d99866f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# class_path3=\"dataset/n01910747/\" #水母\n",
    "# donations_values_list1 = process_batch_images(class_path1)\n",
    "# donations_values_list2 = process_batch_images(class_path2)\n",
    "# donations_values_list3 = process_batch_images(class_path3)\n",
    "# class_path1=\"dataset/n02105505/\" #匈牙利牧羊犬\n",
    "# class_path2=\"dataset/n02101006/\" #戈登雪达犬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68476706-3a72-4d27-98f0-6a1d5f6f845e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity  \n",
    "import numpy as np  \n",
    "\n",
    "def calculate_intra_class_similarity(donations_values_list):  \n",
    "    \"\"\"  \n",
    "    计算类内相似度  \n",
    "\n",
    "    Args:  \n",
    "        donations_values_list (list): 包含一个类别中所有图片的donations_values的列表  \n",
    "\n",
    "    Returns:  \n",
    "        float: 类内相似度的平均值  \n",
    "    \"\"\"  \n",
    "    if len(donations_values_list) < 2:  \n",
    "        return 0.0  # 如果类别中图片少于2张，无法计算相似度  \n",
    "\n",
    "    # 将tensor列表转换为numpy数组  \n",
    "    donations_array = np.stack([tensor.numpy() for tensor in donations_values_list])  \n",
    "\n",
    "    # 计算余弦相似度矩阵  \n",
    "    similarity_matrix = cosine_similarity(donations_array)  \n",
    "\n",
    "    # 取上三角部分（忽略对角线）  \n",
    "    upper_triangle = np.triu(similarity_matrix, k=1)  \n",
    "\n",
    "    # 计算平均值  \n",
    "    num_pairs = len(donations_values_list) * (len(donations_values_list) - 1) // 2  \n",
    "    return np.sum(upper_triangle) / num_pairs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6723ee1-5cf4-4e1e-aba1-3d7b87f4e231",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_inter_class_similarity(class1_values, class2_values):  \n",
    "    \"\"\"  \n",
    "    计算类间相似度  \n",
    "\n",
    "    Args:  \n",
    "        class1_values (list): 类别1的donations_values列表  \n",
    "        class2_values (list): 类别2的donations_values列表  \n",
    "\n",
    "    Returns:  \n",
    "        float: 类间相似度的平均值  \n",
    "    \"\"\"  \n",
    "    if len(class1_values) == 0 or len(class2_values) == 0:  \n",
    "        return 0.0  # 如果某一类别没有数据，无法计算相似度  \n",
    "\n",
    "    # 将tensor列表转换为numpy数组  \n",
    "    class1_array = np.stack([tensor.numpy() for tensor in class1_values])  \n",
    "    class2_array = np.stack([tensor.numpy() for tensor in class2_values])  \n",
    "\n",
    "    # 计算余弦相似度矩阵  \n",
    "    similarity_matrix = cosine_similarity(class1_array, class2_array)  \n",
    "\n",
    "    # 返回平均值  \n",
    "    return np.mean(similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "081e77c5-e8c0-4b83-a619-69e01a97720f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os    \n",
    "\n",
    "def batch_process_and_analyze(dataset_path, class1, class2):  \n",
    "    \"\"\"  \n",
    "    批量处理图片并计算类内和类间相似度  \n",
    "\n",
    "    Args:  \n",
    "        dataset_path (str): 数据集路径，包含两个类别文件夹class1和class2  \n",
    "\n",
    "    Returns:  \n",
    "        tuple: (intra_class_similarity_class1, intra_class_similarity_class2, inter_class_similarity)  \n",
    "    \"\"\"  \n",
    "    class1_path = os.path.join(dataset_path, class1)  \n",
    "    class2_path = os.path.join(dataset_path, class2)  \n",
    "\n",
    "    # 处理两个类别的图片  \n",
    "    class1_values = process_batch_images(class1_path)  \n",
    "    class2_values = process_batch_images(class2_path)  \n",
    "\n",
    "    # 计算类内相似度  \n",
    "    intra_class_similarity_class1 = calculate_intra_class_similarity(class1_values)  \n",
    "    intra_class_similarity_class2 = calculate_intra_class_similarity(class2_values)  \n",
    "\n",
    "    # 计算类间相似度  \n",
    "    inter_class_similarity = calculate_inter_class_similarity(class1_values, class2_values)  \n",
    "\n",
    "    return intra_class_similarity_class1, intra_class_similarity_class2, inter_class_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15fd5582-1cd1-43f7-a649-2dc0796561b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "using device:cuda\n",
      "analyse class:dataset/n01532829/\n",
      "all_imgs : 100\n",
      "\n",
      "using device:cuda\n",
      "analyse class:dataset/n01558993/\n",
      "all_imgs : 100\n",
      "\n",
      "Class1 类内相似度: 0.6820870817550505\n",
      "Class2 类内相似度: 0.685785886205808\n",
      "Class1 和 Class2 类间相似度: 0.6185536980628967\n"
     ]
    }
   ],
   "source": [
    "# class_path1=\"dataset/n02105505/\" #匈牙利牧羊犬\n",
    "# class_path2=\"dataset/n02101006/\" #戈登雪达犬\n",
    "dataset_path = \"dataset/\"  \n",
    "intra_class1, intra_class2, inter_class = batch_process_and_analyze(dataset_path,\"n01532829/\",\"n01558993/\")  \n",
    "\n",
    "print()\n",
    "print(f\"Class1 类内相似度: {intra_class1}\")  \n",
    "print(f\"Class2 类内相似度: {intra_class2}\")  \n",
    "print(f\"Class1 和 Class2 类间相似度: {inter_class}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75a04f59-af7c-48e7-9538-86434a8fa733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "using device:cuda\n",
      "analyse class:dataset/n02105505/\n",
      "all_imgs : 100\n",
      "\n",
      "using device:cuda\n",
      "analyse class:dataset/n02108089/\n",
      "all_imgs : 100\n",
      "\n",
      "Class1 类内相似度: 0.6975414792455809\n",
      "Class2 类内相似度: 0.669719114977904\n",
      "Class1 和 Class2 类间相似度: 0.45617949962615967\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"dataset/\"  \n",
    "# intra_class1, intra_class2, inter_class = batch_process_and_analyze(dataset_path,\"n01532829/\",\"n01558993/\")  \n",
    "intra_class3, intra_class4, inter_class0 = batch_process_and_analyze(dataset_path,\"n02105505/\",\"n02108089/\")\n",
    "print()\n",
    "print(f\"Class1 类内相似度: {intra_class3}\")  \n",
    "print(f\"Class2 类内相似度: {intra_class4}\")  \n",
    "print(f\"Class1 和 Class2 类间相似度: {inter_class0}\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
